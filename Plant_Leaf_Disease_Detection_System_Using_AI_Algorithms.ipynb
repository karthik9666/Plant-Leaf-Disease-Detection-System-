{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef296fa-9305-45e1-b30b-64223bd76ac9",
      "metadata": {
        "id": "7ef296fa-9305-45e1-b30b-64223bd76ac9",
        "outputId": "894ba6d1-b088-43e4-e6da-2c900d3e2831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 38104 images belonging to 13 classes.\n",
            "Found 9458 images belonging to 13 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Windows\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.6799 - loss: 1.1202\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88972, saving model to plant_disease_model.keras\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m866s\u001b[0m 725ms/step - accuracy: 0.6800 - loss: 1.1198 - val_accuracy: 0.8897 - val_loss: 0.3394\n",
            "Epoch 2/5\n",
            "\u001b[1m   1/1190\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:26\u001b[0m 476ms/step - accuracy: 0.8125 - loss: 0.3292\n",
            "Epoch 2: val_accuracy improved from 0.88972 to 1.00000, saving model to plant_disease_model.keras\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.3292 - val_accuracy: 1.0000 - val_loss: 0.1326\n",
            "Epoch 3/5\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - accuracy: 0.9052 - loss: 0.2893\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 720ms/step - accuracy: 0.9052 - loss: 0.2893 - val_accuracy: 0.9386 - val_loss: 0.1949\n",
            "Epoch 4/5\n",
            "\u001b[1m   1/1190\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:29\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0468\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71us/step - accuracy: 1.0000 - loss: 0.0468 - val_accuracy: 1.0000 - val_loss: 0.1052\n",
            "Epoch 5/5\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - accuracy: 0.9336 - loss: 0.1981\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 720ms/step - accuracy: 0.9336 - loss: 0.1981 - val_accuracy: 0.9617 - val_loss: 0.1179\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Define constants and paths\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "TRAIN_PATH = 'Downloads/archive/image data/train'\n",
        "VALID_PATH = 'Downloads/archive/image data/validation'\n",
        "MODEL_PATH = 'plant_disease_model.keras'\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_PATH,target_size=IMAGE_SIZE,batch_size=BATCH_SIZE,class_mode='categorical')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(VALID_PATH,target_size=IMAGE_SIZE,batch_size=BATCH_SIZE,class_mode='categorical')\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks\n",
        "checkpoint = ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(valid_generator, verbose=0)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59413559-78e0-42c8-9f4b-4c29d0a3d8d5",
      "metadata": {
        "id": "59413559-78e0-42c8-9f4b-4c29d0a3d8d5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}